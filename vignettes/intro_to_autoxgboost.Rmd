---
title: "Introduction to AutoxgboostMC"
author: "Florian Pfisterer"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to AutoxgboostMC}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r}
library(mlr)
library(autoxgboostMC)

# Split into train and test data set.
train.idx = sample(seq_len(768), 506)
test.idx = setdiff(seq_len(768), train.idx)
train.task = subsetTask(pid.task, train.idx)
test.task = subsetTask(pid.task, test.idx)
```


## Scenario 1: Optimizing a single measure (Area under the Curve) for a given task.

This scenario reflects the traditional use-case in AutoML scenarios.
Given a dataset we want to obtain a model that optimizes a given performance measure.
Additionally, we might want the process to stop at some point, so that the user
can investigate results and make changes to the search process.

We instantiate a new AutoxgboostMC object with a dataset (Task) and a list of measures.
In this case we choose auc as a measure.
Afterwards we call the `.$fit` method with a time-budget of $15$ seconds.
This runs the AutoML process.

```{r, message=FALSE}
axgb = AutoxgboostMC$new(train.task, measures = list(auc))
axgb$fit(time_budget = 10L, plot = FALSE)
```

We can print the result:

```{r}
axgb
```


If we are not satisfied, we can continue the search process for more iterations:

```{r}
axgb$fit(time_budget = 5L)
```

And then use the resulting model to predict on our test data.

```{r}
# Fit a model from the best
axgb$fit_final_model()
axgb$predict(test.task)
```

and create a Parallel Coordinates Plot:

```{r}
axgb$plot_parallel_coordinates()
```


The resulting model is saved in the `.$final_model` slot.

```{r}
axgb$final_model
```


## Scenario 2: Optimizing Accuracy and Prediction Speed

```{r, warning = FALSE}
axgb = AutoxgboostMC$new(train.task, measures = list(acc, timetrain))
axgb$fit(time_budget = 20L)
```

And visualize:

```{r}
axgb$plot_pareto_front()
axgb$plot_parallel_coordinates()
axgb$plot_opt_result()
```


### Limiting the range of random projections in `parEgo`.

In cases, where we deem a certain region of the Pareto front more important, we can simply
limit the range of the random projections allowed within `parEgo`.

As we are usually not sure, how the trade-off we want to provide looks like, `AutoxgboostMC`
allows us to set a range for the trade-off's we might want to make. This trade-off can be
adapted throughout the search process, to allow focusing on regions that
This is done by setting a range of weights for the first measure in `parEGO`.
By for example setting the range to $(0.0, 0.2)$, we can limit the importance of the first criterion to between
$0$ and $20\%$ in comparison to the prediction time (both are scaled to [0, 1] before applying weights).

We can visualize the impact for different projections:

```{r, warning = FALSE}
axgb$plot_pareto_front_projections(wt_range = c(0.0, 0.2))
axgb$plot_pareto_front_projections(wt_range = c(0.2, 0.8))
axgb$plot_pareto_front_projections(wt_range = c(0.8, 1))
```

And then set the possible projections we deem most important.

```{r}
axgb$optimizer$set_possible_projections(c(0.8, 1))
```

Afterwards, we simply run the `.$fit` method again, to search in the selected space.

```{r}
axgb$fit(time_budget = 10L)
axgb$plot_pareto_front()
```


## Scenario 3: Predictive Accuracy and Fairness

```{r, eval = FALSE}
age_fairf1 = setMeasurePars(fairf1, grouping = function(df) as.factor(df$age > 30))
axgb = AutoxgboostMC$new(train.task, measures = list(acc, age_fairf1))
axgb$fit(time_budget = 30L)
p = axgb$predict(test.task)
```



## Scenario 4: Interpretability, Predictive Accuracy and Robustness

```{r, eval = FALSE}
axgb = AutoxgboostMC$new(train.task, measures = list(auc, interpnf2, robustnoise))
axgb$fit(time_budget = 15L)
p = axgb$predict(test.task)
```

## Scenario 5: Optimizing a subjective measure.

In this scenario, we aim to find a model, that optimizes a measure we can not compute directly from the data, as it heavily depends of our current judgment of the proposed models. This might be a measure that can for example be described as follows:
"I want a model that achieves a very low false positive rate. It needs to be interpretable and fair with respect to a certain characteristic (i.e. the variable race).
Additionally, after looking at diagnosis plots, I can determine, that the relationships my model learns do correspond to the true underlying process,and thus provide a numerical rating for each model."

As a user usually can not look at all intermediate results, we might also want to learn user preferences from a few ratings given by the user and use this data to extrapolate to unrated models, only querying the user for new ratings once in a while.



## Setting Hyperparameters:

```{r, eval = FALSE}
axgb = AutoxgboostMC$new(train.task, measures = list(auc, timepredict))
# Either via setter function
axgb$set_hyperpars(list("" = 25L))
# Or active bindings
axgb$early_stopping_rounds = 5
```


## List of available measures:

### Predictive Performance

A host of measures for predictive performance is available from the package `mlr`.
See `mlr::listMeasures()` or the [mlr Tutorial](https://mlr.mlr-org.com/) for a full list.

### Interpretability
Several measures for interpretability have been defined in [Molnar et al., 2019](https://arxiv.org/abs/1904.03867).
We implement those measures the following measures:

- Curve Complexity

```{r, eval = FALSE}
# Curve Complexity
interpmec
```

- Interaction Strength

```{r, eval = FALSE}
#' Interaction Strength
interpias
```

- Number of features

```{r, eval = FALSE}
# Number of features
interpnf
```

### Fairness

Fairness can be measured with respect to multiple criteria. In our case, we measure difference
with respect to a variable that groups the observational data into 2 groups.

1. Independence

```{r, eval = FALSE}
# Absolute differences of Positive Rate between groups
fairpr
```


2. Sufficiency

```{r, eval = FALSE}
# Absolute differences of F1 Scores between groups
fairf1
```

3. Calibration

```{r, eval = FALSE}
# Absolute differences of Positive Predictive Value between groups
fairppr
```

### Robustness

Robustness can be assessed with respect to multiple criteria. The most important ones incldue:

1. Corruption Robustness

See `?robustnoise` for more info

```{r, eval = FALSE}
# Robustness to feature corruption
robustnoise

# Robustness to featurewise corruption
robustnoiseperfeat
```

2. Adversarial Robustness

```{r, eval = FALSE}
# Not implemented
```

3. Robustness against distribution shift

```{r, eval = FALSE}
# Not implemented
```

### Prediction Speed

Prediction and training speed can be measured from within mlr using `timepredict` and `timetrain`.


## FIXME: UI Design Speccs

App: Starts / Controls AutoML Process and Visualizes results

Tab1: AutoML Process:
Choose a budget, start the process, visualize progress wrt. some measures


Tab2: Pareto Front + Select range for measures + Select importance of measures.

Tab 3: Dataset overview
