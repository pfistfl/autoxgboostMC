---
title: "Introduction to AutoxgboostMC"
author: "Florian Pfisterer"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to AutoxgboostMC}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


```{r}
library(mlr)
# library(autoxgboostMC)
devtools::load_all()

# Split into train and test data set.
train.idx = sample(seq_len(768), 506)
test.idx = setdiff(seq_len(768), train.idx)
train.task = subsetTask(pid.task, train.idx)
test.task = subsetTask(pid.task, test.idx)
```


## Scenario 1: Optimizing a single measure (Area under the Curve) for a given task.

This scenario reflects the traditional use-case in AutoML scenarios.
Given a dataset we want to obtain a model that optimizes a given performance measure.
Additionally, we might want the process to stop at some point, so that the user
can investigate results and make changes to the search process.

We instantiate a new AutoxgboostMC object with a dataset (Task) and a list of measures.
In this case we choose auc as a measure.
Afterwards we call the `.$fit` method with a time-budget of $15$ seconds.
This runs the AutoML process.

```{r}
axgb = AutoxgboostMC$new(train.task, measures = list(auc))
axgb$fit(time_budget = 10L)
```

We can print the result:
```{r}
axgb
```


If we are not satisfied, we can continue the search process for more iterations:

```{r}
axgb$fit(time_budget = 5L)
```

And then use the resulting model to predcit on our test data.

```{r}
# Fit a model from the best
axgb$fit_final_model()
axgb$predict(test.task)
```


```{r}
axgb$plot_parallel_coordinates()
```


The resullting model is saved in the `.$final_model` slot.

```{r}
axgb$final_model
```



## Scenario 2: Optimizing Accuracy and Prediction Speed

```{r}
devtools::load_all()
axgb = AutoxgboostMC$new(train.task, measures = list(acc, timetrain))
axgb$fit(time_budget = 20L)
```

And visualize:

```{r}
# Look at mosmafs pareto front plots
# Pareto front should not be convex
axgb$plot_pareto_front()
axgb$plot_parallel_coordinates()
axgb$plot_opt_result()
```


### Limiting the range of random projections in `parEgo`.

In cases, where we deem a certain region of the pareto front more important, we can simply
limit the range of the random projections allowed within `parEgo`.

As we are usually not sure, how the tradeoff we want to provide looks like, `AutoxgboostMC`
allows us to set a range for the tradeoff's we might want to make. This tradeoff can be
adapted throughout the search process, to allow focusing on regions that
This is done by setting a range of weights for the first measure in `parEGO`.
By for example setting the range to $(0.0, 0.2)$, we can limit the importance of the first criterion to between
$0$ and $20\%$ in comparison to the prediction time (both are scaled to [0, 1] before applying weights).

We can visualize the impac for different projections:

```{r}
axgb$plot_pareto_front_projections(wt_range = c(0.0, 0.2))
axgb$plot_pareto_front_projections(wt_range = c(0.2, 0.8))
axgb$plot_pareto_front_projections(wt_range = c(0.8, 1))
```

And then set the possible projections we deem most important.

```{r}
axgb$optimizer$set_possible_projections(c(0.8, 1))
```

Afterwards, we simply run the `.$fit` method again, to search in the selected space.
```{r}
axgb$fit(time_budget = 20L)
axgb$plot_pareto_front()
```


## Scenario 3: Predictive Accuracy and Fairness

```{r, eval = FALSE}
age_fairf1 = setMeasurePars(fairf1, grouping = function(df) as.factor(df$age > 30))
axgb = AutoxgboostMC$new(train.task, measures = list(acc, age_fairf1))
axgb$fit(time_budget = 30L)
p = axgb$predict(test.task)
```



## Scenario 4: Interpretability, Predictive Accuracy and Robustness

```{r, eval = FALSE}
axgb = AutoxgboostMC$new(train.task, measures = list(auc, interpnf2, robustnoise))
axgb$fit(time_budget = 15L)
p = axgb$predict(test.task)
```

## Scenario 5: Optimizing a subjective measure.

In this scenario, we aim to find a model, that optimizes a measure we can not compute directly from the data, as it heavily depends of our current judgement of the proposed models. This might be a measure that can for example be described as follows:
"I want a model that achieves a very low false positive rate. It needs to be interpretable and fair with respect to a certain characteristic (i.e. the variable race).
Additionally, after looking at diagnosis plots, I can determine, that the relationships my model learns do correspond to the true underlying process,and thus provide a numerical rating for each model."

As a user usually can not look at all intermediate results, we might also want to learn user preferences from a few ratings given by the user and use this data to extrapolate to unrated models, only querying the user for new ratings once in a while.



## Setting Hyperparameters:

```{r, eval = FALSE}
axgb = AutoxgboostMC$new(train.task, measures = list(auc, timepredict))
# Either via setter function
axgb$set_hyperpars(list("" = 25L))
# Or active bindings
axgb$early_stopping_rounds = 5
```


## List of available measures:

### Predictive Performance

A host of measures for predictive performance is available from the package `mlr`.
See `mlr::listMeasures()` or the {mlr Tutorial](https://mlr.mlr-org.com/) for a full list.

### Interpretability
Several measures for interpretability have been defined in [Molnar et al., 2019](https://arxiv.org/abs/1904.03867).
We implement those measures the following measures:

- Curve Complexity

```{r, eval = FALSE}
# Curve Complexity
interpmec
```

- Interaction Strength

```{r, eval = FALSE}
#' Interaction Strength
interpias
```

- Number of features

```{r, eval = FALSE}
# Number of features
interpnf
```

### Fairness

Fairness can be measured with respect to multiple criteria. In our case, we measure difference
with respect to a variable that groups the observational data into 2 groups.

1. Independence

```{r, eval = FALSE}
# Absolute differences of Positive Rate between groups
fairpr
```


2. Sufficiency

```{r, eval = FALSE}
# Absolute differences of F1 Scores between groups
fairf1
```

3. Calibration

```{r, eval = FALSE}
# Absolute differences of Positive Predictive Value between groups
fairppr
```

### Robustness

Robustness can be assessed with respect to multiple criteria. The most important ones incldue:

1. Corruption Robustness

See `?robustnoise` for more info

```{r, eval = FALSE}
# Robustness to feature corruption
robustnoise

# Robustness to featurewise corruption
robustnoiseperfeat
```

2. Adversarial Robustness

```{r, eval = FALSE}
# Not implemented
```

3. Robustness against distribution shift

```{r, eval = FALSE}
# Not implemented
```

### Prediction Speed

Prediction and training speed can be measured from within mlr using `timepredict` and `timetrain`.


## FIXME: UI Design Speccs

App: Starts / Controls AutoML Process and Visualizes results

Tab1: AutoML Process:
Choose a budget, start the process, visualize progress wrt. some measures


Tab2: Pareto Front + Select range for measures + Select importance of measures.

Tab 3: Dataset overview


## Usecase: Adult dataset

We want to demonstrate the main functionalities of AutoxgboostMC in a usecase using the *Adult Dataset*.
It is based on a 1994 Census database and aims to determine whether a person makes over 50K a year.
While we want to predict this binary classification problem as good as possible, we also want to prevent our model from discriminating a person's sex.
To achieve this kind of fairness, we are also optimizing the well known f1 measure within each group.

First, we access the dataset from the *OpenML* database by the `OpenML` R-package.
It also allows to directly transform the dataset into a mlr-task object.

```{r, eval = FALSE}
library(OpenML)
adult = convertOMLDataSetToMlr(getOMLDataSet(1590))
```

The goal for our analysis is to equally optimize the mean missclassification error as well as the fair f1 measure.
Hence, as a second step, we define our fair f1 measure by specifying the grouping variable `sex`.

```{r, eval = FALSE}
data = getTaskData(adult)
sex_fairf1 = setMeasurePars(fairf1, grouping = data$sex)
```

Now its time to create our AutoxgboostMC object.

```{r, eval = FALSE}
axgb = AutoxgboostMC$new(
  task = adult, # adult task
  measures = list(mmce, sex_fairf1) # measures to optimize
)
```

We can now start the training process with some initial iterations.

```{r, eval = FALSE}
set.seed(20190606)
axgb$fit(iterations = 20L, plot = TRUE)
```

After the fitting for the first time we can select a region of the pareto front, we want to focus on and continue the training with more iterations.

```{r, eval = FALSE}
p1 = axgb$plot_pareto_front_projections(wt_range = c(0.1, 0.9))

axgb$optimizer$set_possible_projections(c(0.1, 0.9))
axgb$fit(iterations = 50L, plot = TRUE)
p2 = axgb$plot_pareto_front_projections(wt_range = c(0.1, 0.9))
```


```{r, echo = FALSE}
library(ggplot2)
library(patchwork)
load(file = "results.RData")
plot(p1)
plot(p2)
```


We can repeat this process until we are happy with the results.

```{r, eval = FALSE}
axgb$optimizer$set_possible_projections(c(0.1, 0.9))
axgb$fit(iterations = 50L, plot = TRUE)
p3 = axgb$plot_pareto_front_projections(wt_range = c(0.1, 0.9))
p3
```

```{r, echo = FALSE}
plot(p3)
```

Then, we can nicely plot the results with patchwork.
```{r, eval = FALSE}
library(ggplot2)
library(patchwork)
(p1  + coord_cartesian(xlim = c(0.1, 0.3), ylim = c(0, 0.0015))) +
(p2  + coord_cartesian(xlim = c(0.1, 0.3), ylim = c(0, 0.0015))) +
(p3  + coord_cartesian(xlim = c(0.1, 0.3), ylim = c(0, 0.0015)))
```

```{r}
plot(pareto_plots)
```

Moreover, we can have a look at the parallel coordinates.

```{r, eval = FALSE}
axgb$plot_parallel_coordinates()
```

```{r, echo = FALSE}
load("par_coord_plot.RDS")
plot(par_coord_plot)
```
